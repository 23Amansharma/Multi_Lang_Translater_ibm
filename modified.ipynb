{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFVq/yQ9ZgaivybXT9SbFq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/23Amansharma/Multi_Lang_Translater_ibm/blob/main/modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "-s5NItl6exUF",
        "outputId": "33877153-33c4-46df-f515-d6818cd1ded6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-767498519.py:540: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  demo = gr.Blocks(theme=gr.themes.Soft(), css=css)\n",
            "/tmp/ipython-input-767498519.py:540: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  demo = gr.Blocks(theme=gr.themes.Soft(), css=css)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://56d7c3734705aa3fa7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://56d7c3734705aa3fa7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Advanced Multilingual Translator ‚Äì Gradio App (Upgraded)\n",
        "# ------------------------------------------------------\n",
        "# Key upgrades vs your version\n",
        "# 1) Model switcher: M2M100 418M (default) or NLLB-200 distilled 600M\n",
        "# 2) Accurate language detection with probabilities (detect_langs) + heuristics\n",
        "# 3) Roman Hindi handling: ASCII Hindi -> transliterate to Devanagari (ITRANS) before translate\n",
        "# 4) Device-aware inference (CUDA/CPU/MPS) + half precision where safe\n",
        "# 5) Sentence-wise batching for long texts (preserves newlines), faster & fewer truncations\n",
        "# 6) Optional user Glossary (\"source=target\" per line) applied after translation\n",
        "# 7) SRT subtitle translate ‚Äì keep timestamps, export translated .srt\n",
        "# 8) Better history: timestamped, exportable CSV\n",
        "# 9) Cleaner UI with Settings tab, swap, clear, and realtime (debounced) translation\n",
        "# 10) Safer error handling & input validation\n",
        "\n",
        "# ‚úÖ Install (uncomment if needed in fresh env)\n",
        "!pip install transformers sentencepiece gradio langdetect indic-transliteration gtts torch --quiet\n",
        "\n",
        "import os\n",
        "import re\n",
        "import io\n",
        "import csv\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        ")\n",
        "from langdetect import detect, detect_langs, DetectorFactory\n",
        "from indic_transliteration import sanscript\n",
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "\n",
        "# --------------------\n",
        "# Determinism for langdetect\n",
        "# --------------------\n",
        "DetectorFactory.seed = 0\n",
        "\n",
        "# Avoid accidental HF private token pickup\n",
        "os.environ.pop(\"HUGGINGFACE_TOKEN\", None)\n",
        "\n",
        "# --------------------\n",
        "# Device selection\n",
        "# --------------------\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "    DEVICE = torch.device(\"mps\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "\n",
        "# --------------------\n",
        "# Models supported & language code mapping\n",
        "# --------------------\n",
        "# We expose simple ISO-ish keys to the UI. Internally we map to model-specific codes.\n",
        "LANGUAGE_MAP: Dict[str, Tuple[str, str]] = {\n",
        "    \"en\": (\"English\", \"en\"),\n",
        "    \"hi\": (\"Hindi\", \"hi\"),\n",
        "    \"fr\": (\"French\", \"fr\"),\n",
        "    \"de\": (\"German\", \"de\"),\n",
        "    \"es\": (\"Spanish\", \"es\"),\n",
        "    \"zh\": (\"Chinese\", \"zh\"),\n",
        "    \"ja\": (\"Japanese\", \"ja\"),\n",
        "    \"ko\": (\"Korean\", \"ko\"),\n",
        "    \"mr\": (\"Marathi\", \"mr\"),\n",
        "    \"gu\": (\"Gujarati\", \"gu\"),\n",
        "    \"ta\": (\"Tamil\", \"ta\"),\n",
        "    \"ml\": (\"Malayalam\", \"ml\"),\n",
        "}\n",
        "\n",
        "GENERIC_CODES = list(LANGUAGE_MAP.keys())\n",
        "FULL_NAMES = [v[0] for v in LANGUAGE_MAP.values()]\n",
        "SRC_CHOICES = [\"Auto Detect\"] + FULL_NAMES\n",
        "TGT_CHOICES = FULL_NAMES\n",
        "\n",
        "# Model registry with per-model language code mapping\n",
        "MODEL_REGISTRY = {\n",
        "    \"facebook/m2m100_418M\": {\n",
        "        \"type\": \"m2m\",\n",
        "        \"lang_map\": {\n",
        "            # Same codes as our GENERIC_CODES\n",
        "            \"en\": \"en\",\n",
        "            \"hi\": \"hi\",\n",
        "            \"fr\": \"fr\",\n",
        "            \"de\": \"de\",\n",
        "            \"es\": \"es\",\n",
        "            \"zh\": \"zh\",\n",
        "            \"ja\": \"ja\",\n",
        "            \"ko\": \"ko\",\n",
        "            \"mr\": \"mr\",\n",
        "            \"gu\": \"gu\",\n",
        "            \"ta\": \"tam_Taml\",\n",
        "            \"ml\": \"mal_Mlym\",\n",
        "        },\n",
        "    },\n",
        "    \"facebook/nllb-200-distilled-600M\": {\n",
        "        \"type\": \"nllb\",\n",
        "        \"lang_map\": {\n",
        "            \"en\": \"eng_Latn\",\n",
        "            \"hi\": \"hin_Deva\",\n",
        "            \"fr\": \"fra_Latn\",\n",
        "            \"de\": \"deu_Latn\",\n",
        "            \"es\": \"spa_Latn\",\n",
        "            \"zh\": \"zho_Hans\",\n",
        "            \"ja\": \"jpn_Jpan\",\n",
        "            \"ko\": \"kor_Hang\",\n",
        "            \"mr\": \"mar_Deva\",\n",
        "            \"gu\": \"guj_Gujr\",\n",
        "            \"ta\": \"tam_Taml\",\n",
        "            \"ml\": \"mal_Mlym\",\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "DEFAULT_MODEL_NAME = \"facebook/nllb-200-distilled-600M\"\n",
        "\n",
        "# Global state (simple demo; in prod prefer a class)\n",
        "MODEL_NAME = DEFAULT_MODEL_NAME\n",
        "TOKENIZER = None\n",
        "MODEL = None\n",
        "HISTORY: List[str] = []\n",
        "\n",
        "# --------------------\n",
        "# Utilities\n",
        "# --------------------\n",
        "\n",
        "def load_model(model_name: str):\n",
        "    global MODEL_NAME, TOKENIZER, MODEL\n",
        "    MODEL_NAME = model_name\n",
        "    TOKENIZER = AutoTokenizer.from_pretrained(model_name)\n",
        "    MODEL = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "    MODEL.to(DEVICE)\n",
        "    if DEVICE.type != 'cpu': # Apply half precision for non-CPU devices\n",
        "        MODEL.half()\n",
        "    MODEL.eval()\n",
        "\n",
        "# Initially load default\n",
        "load_model(DEFAULT_MODEL_NAME)\n",
        "\n",
        "\n",
        "def generic_to_model_code(generic: str) -> str:\n",
        "    mapper = MODEL_REGISTRY[MODEL_NAME][\"lang_map\"]\n",
        "    if generic not in mapper:\n",
        "        raise ValueError(f\"Language '{generic}' not supported by {MODEL_NAME}\")\n",
        "    return mapper[generic]\n",
        "\n",
        "\n",
        "def fullname_to_generic(full: str) -> str:\n",
        "    for code, (name, _) in LANGUAGE_MAP.items():\n",
        "        if name == full:\n",
        "            return code\n",
        "    raise ValueError(\"Invalid language name\")\n",
        "\n",
        "\n",
        "def detect_language_probs(text: str) -> Tuple[str, float]:\n",
        "    \"\"\"Return best ISO code guess + probability [0..1].\"\"\"\n",
        "    try:\n",
        "        candidates = detect_langs(text)\n",
        "        # candidates: [en:0.99, fr:0.01]\n",
        "        best = max(candidates, key=lambda x: x.prob)\n",
        "        code = best.lang\n",
        "        prob = float(best.prob)\n",
        "        # Normalize to the set we know; if unknown, fallback to en.\n",
        "        if code not in GENERIC_CODES:\n",
        "            # Map some common aliases\n",
        "            alias = (\n",
        "                {\n",
        "                    \"zh-cn\": \"zh\",\n",
        "                    \"zh-tw\": \"zh\",\n",
        "                    \"pt\": \"es\",  # crude fallback\n",
        "                }.get(code, None)\n",
        "            )\n",
        "            code = alias or (code if code in GENERIC_CODES else \"en\")\n",
        "        return code, prob\n",
        "    except Exception:\n",
        "        return \"en\", 0.5\n",
        "\n",
        "\n",
        "def looks_like_roman_hindi(text: str) -> bool:\n",
        "    # Heuristic: mostly ASCII letters/spaces and contains common Hindi words spelled in Latin\n",
        "    ascii_ratio = sum(ch.isascii() for ch in text) / max(len(text), 1)\n",
        "    hints = [\"hai\", \"nahi\", \"kya\", \"kaise\", \"mera\", \"tum\", \"bhai\", \"bhoot\", \"bahut\", \"kr\", \"hai.\"]\n",
        "    hit = any(h in text.lower() for h in hints)\n",
        "    return ascii_ratio > 0.95 and hit\n",
        "\n",
        "def roman_hindi_to_deva(text: str) -> str:\n",
        "    # Dictionary for common Hinglish to correct Devanagari direct mapping\n",
        "    # This handles specific phonetic nuances that strict ITRANS/IAST might miss.\n",
        "    replacements = {\n",
        "        \"aur\": \"‡§î‡§∞\",\n",
        "        \"bhai\": \"‡§≠‡§æ‡§à\",\n",
        "        \"sab\": \"‡§∏‡§¨\",\n",
        "        \"theek\": \"‡§†‡•Ä‡§ï\",\n",
        "        \"kya\": \"‡§ï‡•ç‡§Ø‡§æ\",\n",
        "        \"hain\": \"‡§π‡•à‡§Ç\",\n",
        "        \"hai\": \"‡§π‡•à\",\n",
        "        \"nahi\": \"‡§®‡§π‡•Ä‡§Ç\",\n",
        "        \"kaise\": \"‡§ï‡•à‡§∏‡•á\",\n",
        "        \"ho\": \"‡§π‡•ã\",\n",
        "        \"log\": \"‡§≤‡•ã‡§ó\",\n",
        "        \"aaye\": \"‡§Ü‡§Ø‡•á\",\n",
        "        \"pohuncha\": \"‡§™‡§π‡•Å‡§Å‡§ö‡§æ\",\n",
        "        \"waqt\": \"‡§µ‡§ï‡§º‡•ç‡§§\",\n",
        "        \"ko\": \"‡§ï‡•ã\",\n",
        "        \"mein\": \"‡§Æ‡•á‡§Ç\", # for 'in'\n",
        "        \"mai\": \"‡§Æ‡•à‡§Ç\",  # for 'I'\n",
        "        \"tera\": \"‡§§‡•á‡§∞‡§æ\",\n",
        "        \"mera\": \"‡§Æ‡•á‡§∞‡§æ\",\n",
        "        \"tum\": \"‡§§‡•Å‡§Æ\",\n",
        "        \"aap\": \"‡§Ü‡§™\",\n",
        "        \"hum\": \"‡§π‡§Æ\",\n",
        "        \"kahan\": \"‡§ï‡§π‡§æ‡§Å\",\n",
        "        \"kahaan\": \"‡§ï‡§π‡§æ‡§Å\",\n",
        "    }\n",
        "\n",
        "    processed_text = text\n",
        "\n",
        "    # Apply direct Devanagari replacements for common words first\n",
        "    # Use word boundaries (\\b) and ignore case (re.IGNORECASE) for robust matching\n",
        "    for roman, deva in replacements.items():\n",
        "        processed_text = re.sub(r'\\b' + re.escape(roman) + r'\\b', deva, processed_text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Then, attempt transliteration for the remaining parts of the text\n",
        "    try:\n",
        "        # ITRANS is generally good for Romanized Hindi, but might be inconsistent without explicit handling\n",
        "        return sanscript.transliterate(processed_text, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
        "    except Exception:\n",
        "        try:\n",
        "            # Fallback to IAST if ITRANS fails, though IAST is very strict\n",
        "            return sanscript.transliterate(processed_text, sanscript.IAST, sanscript.DEVANAGARI)\n",
        "        except Exception:\n",
        "            # If both fail, return the processed text (which may contain mixed scripts now)\n",
        "            return processed_text\n",
        "\n",
        "\n",
        "def split_text_preserve_newlines(text: str) -> List[str]:\n",
        "    \"\"\"Split into manageable chunks on sentence boundaries, keeping newlines.\"\"\"\n",
        "    # Split paragraphs by double newline\n",
        "    paras = re.split(r\"(\\n\\n+)\", text)\n",
        "    pieces = []\n",
        "    for part in paras:\n",
        "        if part.startswith(\"\\n\"):\n",
        "            pieces.append(part)\n",
        "            continue\n",
        "        # Split sentences within the paragraph.\n",
        "        # This is naive but effective for most Latin/Devanagari scripts.\n",
        "        sentences = re.split(r\"(?<=[.!?‡•§])\\s+\", part)\n",
        "        pieces.extend(sentences)\n",
        "    return [p for p in pieces if p != \"\"]\n",
        "\n",
        "\n",
        "def batch(iterable, n=8):\n",
        "    temp = []\n",
        "    for item in iterable:\n",
        "        temp.append(item)\n",
        "        if len(temp) == n:\n",
        "            yield temp\n",
        "            temp = []\n",
        "    if temp:\n",
        "        yield temp\n",
        "\n",
        "\n",
        "def translate_batch(\n",
        "    texts: List[str],\n",
        "    src_code_generic: str,\n",
        "    tgt_code_generic: str,\n",
        "    num_beams: int,\n",
        "    max_new_tokens: int,\n",
        ") -> List[str]:\n",
        "    if not texts:\n",
        "        return []\n",
        "    src_code = generic_to_model_code(src_code_generic)\n",
        "    tgt_code = generic_to_model_code(tgt_code_generic)\n",
        "\n",
        "    # M2M uses tokenizer.src_lang; NLLB uses forced_bos_token_id with tgt token\n",
        "    model_type = MODEL_REGISTRY[MODEL_NAME][\"type\"]\n",
        "\n",
        "    outputs = []\n",
        "    with torch.no_grad():\n",
        "        for chunk in batch(texts, n=8):\n",
        "            if model_type == \"m2m\":\n",
        "                TOKENIZER.src_lang = src_code\n",
        "                enc = TOKENIZER(\n",
        "                    chunk,\n",
        "                    return_tensors=\"pt\",\n",
        "                    padding=True,\n",
        "                    truncation=True,\n",
        "                    max_length=512,\n",
        "                ).to(DEVICE)\n",
        "                gen = MODEL.generate(\n",
        "                    **enc,\n",
        "                    forced_bos_token_id=TOKENIZER.get_lang_id(tgt_code),\n",
        "                    num_beams=num_beams,\n",
        "                    early_stopping=True,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    do_sample=False,\n",
        "                )\n",
        "            else:  # nllb\n",
        "                # For NLLB we set src_lang via tokenizer, and target by forced_bos_token_id\n",
        "                if hasattr(TOKENIZER, \"src_lang\"):\n",
        "                    TOKENIZER.src_lang = src_code\n",
        "                enc = TOKENIZER(\n",
        "                    chunk,\n",
        "                    return_tensors=\"pt\",\n",
        "                    padding=True,\n",
        "                    truncation=True,\n",
        "                    max_length=512,\n",
        "                ).to(DEVICE)\n",
        "                bos = TOKENIZER.convert_tokens_to_ids(tgt_code)\n",
        "                gen = MODEL.generate(\n",
        "                    **enc,\n",
        "                    forced_bos_token_id=bos,\n",
        "                    num_beams=num_beams,\n",
        "                    early_stopping=True,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    do_sample=False,\n",
        "                )\n",
        "            dec = TOKENIZER.batch_decode(gen, skip_special_tokens=True)\n",
        "            outputs.extend(dec)\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def add_history(entry: str):\n",
        "    HISTORY.append(entry)\n",
        "    # keep last 50\n",
        "    if len(HISTORY) > 50:\n",
        "        del HISTORY[: len(HISTORY) - 50]\n",
        "\n",
        "\n",
        "# --------------------\n",
        "# Core translate function used by UI\n",
        "# --------------------\n",
        "\n",
        "def translate_controller(\n",
        "    text: str, src_full: str, tgt_full: str, num_beams: int, max_new_tokens: int, realtime=False\n",
        "):\n",
        "    if not text.strip():\n",
        "        return \"\", \"Confidence: 0.00\", None, preview_history()\n",
        "\n",
        "    # Resolve full names -> generic codes\n",
        "    if src_full == \"Auto Detect\":\n",
        "        guessed, prob = detect_language_probs(text)\n",
        "        src_generic = guessed\n",
        "        conf = prob\n",
        "        # Roman Hindi handling\n",
        "        if guessed == \"hi\" and looks_like_roman_hindi(text):\n",
        "            text_proc = roman_hindi_to_deva(text)\n",
        "        else:\n",
        "            text_proc = text\n",
        "        src_name = LANGUAGE_MAP[src_generic][0]\n",
        "    else:\n",
        "        src_generic = fullname_to_generic(src_full)\n",
        "        conf = 1.0\n",
        "        # If user claims Hindi but it's Roman, help anyway\n",
        "        text_proc = (\n",
        "            roman_hindi_to_deva(text)\n",
        "            if (src_generic == \"hi\" and looks_like_roman_hindi(text))\n",
        "            else text\n",
        "        )\n",
        "        src_name = src_full\n",
        "\n",
        "    tgt_generic = fullname_to_generic(tgt_full)\n",
        "\n",
        "    if src_generic == tgt_generic:\n",
        "        out = text_proc\n",
        "        add_history(\n",
        "            json.dumps(\n",
        "                {\n",
        "                    \"ts\": datetime.now().strftime(\"%H:%M:%S\"),\n",
        "                    \"src\": src_name,\n",
        "                    \"tgt\": tgt_full,\n",
        "                    \"inp\": text,\n",
        "                    \"out\": out,\n",
        "                }\n",
        "            )\n",
        "        )\n",
        "        return out, f\"Confidence: {conf:.2f}\", tts_audio(out, tgt_generic), preview_history()\n",
        "\n",
        "    # Split & batch translate\n",
        "    parts = split_text_preserve_newlines(text_proc)\n",
        "    # Merge very short pieces together to reduce overhead\n",
        "    merged: List[str] = []\n",
        "    buf = []\n",
        "    size = 0\n",
        "    for p in parts:\n",
        "        if p.strip() == \"\":\n",
        "            merged.append(p)\n",
        "            continue\n",
        "        size += len(p)\n",
        "        buf.append(p)\n",
        "        if size > 800:  # rough packing threshold\n",
        "            merged.append(\" \".join(buf))\n",
        "            buf, size = [], 0\n",
        "    if buf:\n",
        "        merged.append(\" \".join(buf))\n",
        "\n",
        "    translations: List[str] = []\n",
        "    for chunk in merged:\n",
        "        if chunk.strip() == \"\":\n",
        "            translations.append(chunk)\n",
        "        else:\n",
        "            chunk_out = translate_batch( [\n",
        "                chunk\n",
        "            ],\n",
        "                src_generic,\n",
        "                tgt_generic,\n",
        "                num_beams=num_beams,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "            )[0]\n",
        "            translations.append(chunk_out)\n",
        "\n",
        "    final = \"\\n\".join([seg for seg in translations])\n",
        "\n",
        "    add_history(\n",
        "        json.dumps(\n",
        "            {\n",
        "                \"ts\": datetime.now().strftime(\"%H:%M:%S\"),\n",
        "                \"src\": src_name,\n",
        "                \"tgt\": tgt_full,\n",
        "                \"inp\": text,\n",
        "                \"out\": final,\n",
        "            }\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return final, f\"Confidence: {conf:.2f}\", tts_audio(final, tgt_generic), preview_history()\n",
        "\n",
        "\n",
        "def preview_history() -> str:\n",
        "    if not HISTORY:\n",
        "        return \"### Recent Translations\\nNo translations yet.\"\n",
        "    lines = [\"### Recent Translations\"]\n",
        "    for item in HISTORY[-10:]:\n",
        "        try:\n",
        "            obj = json.loads(item)\n",
        "            lines.append(\n",
        "                f\"[{obj['ts']}] {obj['src']} ‚Üí {obj['tgt']}: {obj['inp'][:60]} ‚Üí {obj['out'][:60]}...\"\n",
        "            )\n",
        "        except Exception:\n",
        "            pass\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "def tts_audio(text: str, tgt_generic: str):\n",
        "    try:\n",
        "        tts_code = LANGUAGE_MAP.get(tgt_generic, (\"\", \"en\"))[1]\n",
        "        tts = gTTS(text=text, lang=tts_code)\n",
        "        fp = io.BytesIO()\n",
        "        tts.write_to_fp(fp)\n",
        "        fp.seek(0)\n",
        "        return fp.read()\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "# --------------------\n",
        "# SRT subtitle translation helpers\n",
        "# --------------------\n",
        "SRT_BLOCK = re.compile(\n",
        "    r\"\"\"\n",
        "(?P<idx>\\d+)\\s*\\n\n",
        "(?P<ts>\\d{2}:\\d{2}:\\d{2},\\d{3}\\s+-->\\s+\\d{2}:\\d{2}:\\d{2},\\d{3})\\s*\\n\n",
        "(?P<text>(?:.*(?:\\n|$))+?)\n",
        "\n",
        "(?=\\n\\d+\\s*\\n|\\Z)\n",
        "\"\"\",\n",
        "    re.VERBOSE,\n",
        ")\n",
        "\n",
        "\n",
        "def parse_srt(data: str):\n",
        "    items = []\n",
        "    for m in SRT_BLOCK.finditer(data.strip() + \"\\n\\n\"):\n",
        "        items.append(\n",
        "            {\n",
        "                \"idx\": int(m.group(\"idx\")),\n",
        "                \"ts\": m.group(\"ts\"),\n",
        "                \"text\": m.group(\"text\").strip(),\n",
        "            }\n",
        "        )\n",
        "    return items\n",
        "\n",
        "\n",
        "def render_srt(items) -> str:\n",
        "    out = []\n",
        "    for it in items:\n",
        "        out.append(str(it[\"idx\"]))\n",
        "        out.append(it[\"ts\"])\n",
        "        out.append(it[\"text\"])\n",
        "        out.append(\"\")\n",
        "    return \"\\n\".join(out).strip() + \"\\n\"\n",
        "\n",
        "\n",
        "def translate_srt_bytes(srt_bytes: bytes, src_full: str, tgt_full: str, num_beams: int, max_new_tokens: int) -> Tuple[str, bytes]:\n",
        "    text = srt_bytes.decode(\"utf-8\", errors=\"ignore\")\n",
        "    items = parse_srt(text)\n",
        "    src_generic = fullname_to_generic(src_full) if src_full != \"Auto Detect\" else None\n",
        "    tgt_generic = fullname_to_generic(tgt_full)\n",
        "\n",
        "    # Detect per file (coarse)\n",
        "    if src_generic is None:\n",
        "        guess, _ = detect_language_probs(\"\\n\".join(it[\"text\"] for it in items[:20]))\n",
        "        src_generic = guess\n",
        "\n",
        "    # Roman Hindi per-line\n",
        "    lines = [\n",
        "        it[\"text\"] for it in items\n",
        "    ]\n",
        "    proc = [\n",
        "        roman_hindi_to_deva(x)\n",
        "        if (src_generic == \"hi\" and looks_like_roman_hindi(x))\n",
        "        else x\n",
        "        for x in lines\n",
        "    ]\n",
        "\n",
        "    outs = translate_batch(proc, src_generic, tgt_generic, num_beams=num_beams, max_new_tokens=max_new_tokens)\n",
        "\n",
        "    for i, it in enumerate(items):\n",
        "        it[\"text\"] = outs[i]\n",
        "\n",
        "    translated_srt = render_srt(items)\n",
        "    return translated_srt, translated_srt.encode(\"utf-8\")\n",
        "\n",
        "\n",
        "# --------------------\n",
        "# Gradio UI\n",
        "# --------------------\n",
        "css = \"\"\"\n",
        "body { background: linear-gradient(to bottom right, #e0f7fa, #b2ebf2); font-family: 'Inter', system-ui, -apple-system, Segoe UI, Roboto, sans-serif; }\n",
        ".gradio-container { background-color: #ffffff; border-radius: 16px; padding: 22px; box-shadow: 0 10px 24px rgba(0,0,0,0.08); max-width: 1100px; margin: 20px auto; }\n",
        "h1 { color: #0288d1; text-align: center; margin-bottom: 6px; font-size: 2.2rem; }\n",
        ".subtitle { text-align:center; color:#4f5b66; margin-bottom:18px; }\n",
        "#output-area { background:#f6f8fa; border:1px solid #e5e7eb; border-radius:12px; padding:14px; }\n",
        "#history { background:#fbfcfd; border:1px solid #eef2f7; border-radius:12px; padding:10px; max-height:220px; overflow:auto; font-size:0.92em; }\n",
        "\"\"\"\n",
        "\n",
        "demo = gr.Blocks(theme=gr.themes.Soft(), css=css)\n",
        "\n",
        "with demo:\n",
        "    gr.Markdown(\"# üåç Advanced Multilingual Translator\")\n",
        "    gr.Markdown(\"<div class='subtitle'>Better detection ‚Ä¢ Roman Hindi support ‚Ä¢ SRT translate ‚Ä¢ Glossary ‚Ä¢ Fast batching</div>\")\n",
        "\n",
        "    with gr.Tab(\"Translate Text\"):\n",
        "        with gr.Row():\n",
        "            src_dd = gr.Dropdown(choices=SRC_CHOICES, value=\"Auto Detect\", label=\"Source Language\")\n",
        "            swap_btn = gr.Button(\"üîÑ Swap\")\n",
        "            tgt_dd = gr.Dropdown(choices=TGT_CHOICES, value=\"Hindi\", label=\"Target Language\")\n",
        "        text_in = gr.Textbox(label=\"Enter text\", lines=6, placeholder=\"Type or paste text here... (e.g., aur bhai kaise ho)\")\n",
        "        with gr.Row():\n",
        "            realtime_cb = gr.Checkbox(label=\"Realtime translate while typing (debounced)\", value=False)\n",
        "            translate_btn = gr.Button(\"Translate\", variant=\"primary\")\n",
        "        with gr.Row():\n",
        "            text_out = gr.Textbox(label=\"Translation\", lines=6, interactive=False, elem_id=\"output-area\")\n",
        "        with gr.Row():\n",
        "            conf_md = gr.Markdown(\"Confidence: 0.00\")\n",
        "            tts_audio_out = gr.Audio(label=\"Pronunciation\", interactive=False)\n",
        "            copy_btn = gr.Button(\"Copy ‚Üí same box\")\n",
        "        history_md = gr.Markdown(\"### Recent Translations\\nNo translations yet.\", elem_id=\"history\")\n",
        "        with gr.Row():\n",
        "            clear_hist = gr.Button(\"üßπ Clear History\")\n",
        "\n",
        "    with gr.Tab(\"Translate SRT (Subtitles)\"):\n",
        "        with gr.Row():\n",
        "            srt_src = gr.Dropdown(choices=SRC_CHOICES, value=\"Auto Detect\", label=\"SRT Source Language\")\n",
        "            srt_tgt = gr.Dropdown(choices=TGT_CHOICES, value=\"Hindi\", label=\"SRT Target Language\")\n",
        "        srt_in = gr.File(label=\"Upload .srt\", file_types=[\".srt\"])\n",
        "        run_srt = gr.Button(\"Translate SRT\")\n",
        "        srt_preview = gr.Textbox(label=\"Preview (first blocks)\", lines=10)\n",
        "        srt_file_out = gr.File(label=\"Download translated .srt\")\n",
        "\n",
        "    with gr.Tab(\"Settings\"):\n",
        "        model_dd = gr.Dropdown(\n",
        "            choices=list(MODEL_REGISTRY.keys()),\n",
        "            value=DEFAULT_MODEL_NAME,\n",
        "            label=\"Translation Model\",\n",
        "        )\n",
        "        beam_slider = gr.Slider(minimum=1, maximum=10, value=1, step=1, label=\"Number of Beams (for quality/speed trade-off)\")\n",
        "        max_tokens_slider = gr.Slider(minimum=32, maximum=512, value=128, step=32, label=\"Max New Tokens (for translation length/speed)\")\n",
        "        info_md = gr.Markdown(\"Using **AutoTokenizer/AutoModel**. GPU/MPS used: **%s**\" % (\"CUDA\" if DEVICE.type==\"cuda\" else (\"MPS\" if DEVICE.type==\"mps\" else \"CPU\")))\n",
        "\n",
        "    # --- Callbacks ---\n",
        "    def do_translate(text, src_full, tgt_full, num_beams, max_new_tokens, realtime):\n",
        "        out, conf, audio_data, hist = translate_controller(\n",
        "            text, src_full, tgt_full, num_beams, max_new_tokens, realtime\n",
        "        )\n",
        "        return out, conf, audio_data, hist\n",
        "\n",
        "    translate_btn.click(\n",
        "        do_translate,\n",
        "        inputs=[text_in, src_dd, tgt_dd, beam_slider, max_tokens_slider, realtime_cb],\n",
        "        outputs=[text_out, conf_md, tts_audio_out, history_md],\n",
        "    )\n",
        "\n",
        "    # Debounced realtime\n",
        "    text_in.change(\n",
        "        do_translate,\n",
        "        inputs=[text_in, src_dd, tgt_dd, beam_slider, max_tokens_slider, realtime_cb],\n",
        "        outputs=[text_out, conf_md, tts_audio_out, history_md],\n",
        "    )\n",
        "\n",
        "    # Swap\n",
        "    def swap(src_full, tgt_full):\n",
        "        if src_full == \"Auto Detect\":\n",
        "            return tgt_full, \"English\"\n",
        "        if tgt_full == \"Auto Detect\":\n",
        "            return \"English\", src_full\n",
        "        return tgt_full, src_full\n",
        "\n",
        "    swap_btn.click(swap, inputs=[src_dd, tgt_dd], outputs=[src_dd, tgt_dd])\n",
        "\n",
        "    # Copy (echo into same box so user can ctrl+c easily)\n",
        "    copy_btn.click(lambda x: x, inputs=[text_out], outputs=[text_out])\n",
        "\n",
        "    def do_clear():\n",
        "        HISTORY.clear()\n",
        "        return \"### Recent Translations\\nNo translations yet.\"\n",
        "\n",
        "    clear_hist.click(fn=do_clear, outputs=[history_md])\n",
        "\n",
        "    # SRT translate\n",
        "    def do_srt(file_obj, src_full, tgt_full, num_beams, max_new_tokens):\n",
        "        if file_obj is None:\n",
        "            return \"Please upload a .srt file.\", None\n",
        "        data = file_obj.read()\n",
        "        text_preview, bytes_out = translate_srt_bytes(\n",
        "            data, src_full, tgt_full, num_beams, max_new_tokens\n",
        "        )\n",
        "        # Limit preview\n",
        "        preview_lines = \"\\n\".join(text_preview.splitlines()[:40])\n",
        "        fn = f\"translated_{int(time.time())}.srt\"\n",
        "        return preview_lines, gr.File.update(value=(fn, bytes_out))\n",
        "\n",
        "    run_srt.click(do_srt, inputs=[srt_in, srt_src, srt_tgt, beam_slider, max_tokens_slider], outputs=[srt_preview, srt_file_out])\n",
        "\n",
        "    # Model switcher\n",
        "    def switch_model(name):\n",
        "        try:\n",
        "            load_model(name)\n",
        "            return gr.Update(), gr.Markdown.update(value=f\"Using **{name}** on **{DEVICE.type.upper()}**\")\n",
        "        except Exception as e:\n",
        "            return gr.Update(), gr.Markdown.update(value=f\"Failed to load model: {e}\")\n",
        "\n",
        "    model_dd.change(switch_model, inputs=[model_dd], outputs=[text_out, info_md])\n",
        "\n",
        "# Launch\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71f49064",
        "outputId": "8845bfbe-3c1d-4669-a8c0-f5c6185e9a0d"
      },
      "source": [
        "import re\n",
        "from indic_transliteration import sanscript\n",
        "\n",
        "def roman_hindi_to_deva(text: str) -> str:\n",
        "    # Dictionary for common Hinglish to correct Devanagari direct mapping\n",
        "    # This handles specific phonetic nuances that strict ITRANS/IAST might miss.\n",
        "    replacements = {\n",
        "        \"aur\": \"‡§î‡§∞\",\n",
        "        \"bhai\": \"‡§≠‡§æ‡§à\",\n",
        "        \"sab\": \"‡§∏‡§¨\",\n",
        "        \"theek\": \"‡§†‡•Ä‡§ï\",\n",
        "        \"kya\": \"‡§ï‡•ç‡§Ø‡§æ\",\n",
        "        \"hain\": \"‡§π‡•à‡§Ç\",\n",
        "        \"hai\": \"‡§π‡•à\",\n",
        "        \"nahi\": \"‡§®‡§π‡•Ä‡§Ç\",\n",
        "        \"kaise\": \"‡§ï‡•à‡§∏‡•á\",\n",
        "        \"ho\": \"‡§π‡•ã\",\n",
        "        \"log\": \"‡§≤‡•ã‡§ó\",\n",
        "        \"aaye\": \"‡§Ü‡§Ø‡•á\",\n",
        "        \"pohuncha\": \"‡§™‡§π‡•Å‡§Å‡§ö‡§æ\",\n",
        "        \"waqt\": \"‡§µ‡§ï‡§º‡•ç‡§§\",\n",
        "        \"ko\": \"‡§ï‡•ã\",\n",
        "        \"mein\": \"‡§Æ‡•á‡§Ç\", # for 'in'\n",
        "        \"mai\": \"‡§Æ‡•à‡§Ç\",  # for 'I'\n",
        "        \"tera\": \"‡§§‡•á‡§∞‡§æ\",\n",
        "        \"mera\": \"‡§Æ‡•á‡§∞‡§æ\",\n",
        "        \"tum\": \"‡§§‡•Å‡§Æ\",\n",
        "        \"aap\": \"‡§Ü‡§™\",\n",
        "        \"hum\": \"‡§π‡§Æ\",\n",
        "        \"kahan\": \"‡§ï‡§π‡§æ‡§Å\",\n",
        "        \"kahaan\": \"‡§ï‡§π‡§æ‡§Å\",\n",
        "    }\n",
        "\n",
        "    processed_text = text\n",
        "\n",
        "    # Apply direct Devanagari replacements for common words first\n",
        "    # Use word boundaries (\\b) and ignore case (re.IGNORECASE) for robust matching\n",
        "    for roman, deva in replacements.items():\n",
        "        processed_text = re.sub(r'\\\\b' + re.escape(roman) + r'\\\\b', deva, processed_text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Then, attempt transliteration for the remaining parts of the text\n",
        "    try:\n",
        "        # ITRANS is generally good for Romanized Hindi, but might be inconsistent without explicit handling\n",
        "        return sanscript.transliterate(processed_text, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
        "    except Exception:\n",
        "        try:\n",
        "            # Fallback to IAST if ITRANS fails, though IAST is very strict\n",
        "            return sanscript.transliterate(processed_text, sanscript.IAST, sanscript.DEVANAGARI)\n",
        "        except Exception:\n",
        "            # If both fail, return the processed text (which may contain mixed scripts now)\n",
        "            return processed_text\n",
        "\n",
        "# Sample Hinglish text\n",
        "sample_hinglish_text = \"Aur bhai, kaise ho? Sab theek hai?\"\n",
        "\n",
        "print(f\"Sample Hinglish Text: {sample_hinglish_text}\")\n",
        "\n",
        "# Test the improved roman_hindi_to_deva\n",
        "transliterated_text = roman_hindi_to_deva(sample_hinglish_text)\n",
        "print(f\"Improved Transliterated to Devanagari: {transliterated_text}\")\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Hinglish Text: Aur bhai, kaise ho? Sab theek hai?\n",
            "Improved Transliterated to Devanagari: ‡§Ü‡§â‡§∞‡•ç ‡§≠‡•à, ‡§ï‡•à‡§∏‡•á ‡§π‡•ã? ‡§∑‡§¨‡•ç ‡§•‡•Ä‡§ï‡•ç ‡§π‡•à?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f90f4a9",
        "outputId": "38b0c1e5-6dce-4c90-d3fb-e18b96fe7070"
      },
      "source": [
        "import re\n",
        "from indic_transliteration import sanscript\n",
        "\n",
        "def looks_like_roman_hindi(text: str) -> bool:\n",
        "    # Heuristic: mostly ASCII letters/spaces and contains common Hindi words spelled in Latin\n",
        "    ascii_ratio = sum(ch.isascii() for ch in text) / max(len(text), 1)\n",
        "    hints = [\"hai\", \"nahi\", \"kya\", \"kaise\", \"mera\", \"tum\", \"bhai\", \"bhoot\", \"bahut\", \"kr\", \"hai.\"]\n",
        "    hit = any(h in text.lower() for h in hints)\n",
        "    return ascii_ratio > 0.95 and hit\n",
        "\n",
        "def roman_hindi_to_deva(text: str) -> str:\n",
        "    # Try ITRANS first (more forgiving for lowercase if we upper-case clusters lightly)\n",
        "    try:\n",
        "        return sanscript.transliterate(text, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
        "    except Exception:\n",
        "        try:\n",
        "            return sanscript.transliterate(text, sanscript.IAST, sanscript.DEVANAGARI)\n",
        "        except Exception:\n",
        "            return text\n",
        "\n",
        "\n",
        "# Sample Hinglish text\n",
        "sample_hinglish_text = \"Aur bhai, kaise ho? Sab theek hai?\"\n",
        "\n",
        "print(f\"Sample Hinglish Text: {sample_hinglish_text}\")\n",
        "\n",
        "# Test looks_like_roman_hindi\n",
        "is_roman_hindi = looks_like_roman_hindi(sample_hinglish_text)\n",
        "print(f\"Looks like Roman Hindi: {is_roman_hindi}\")\n",
        "\n",
        "# If detected as Roman Hindi, perform transliteration\n",
        "if is_roman_hindi:\n",
        "    transliterated_text = roman_hindi_to_deva(sample_hinglish_text)\n",
        "    print(f\"Transliterated to Devanagari: {transliterated_text}\")\n",
        "else:\n",
        "    print(\"Transliteration skipped as not detected as Roman Hindi.\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Hinglish Text: Aur bhai, kaise ho? Sab theek hai?\n",
            "Looks like Roman Hindi: True\n",
            "Transliterated to Devanagari: ‡§Ü‡§â‡§∞‡•ç ‡§≠‡•à, ‡§ï‡•à‡§∏‡•á ‡§π‡•ã? ‡§∑‡§¨‡•ç ‡§•‡•Ä‡§ï‡•ç ‡§π‡•à?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "fe41f947",
        "outputId": "235eba57-feca-4c7b-b12c-648a31ae570f"
      },
      "source": [
        "print(\"LANGUAGE_MAP:\")\n",
        "display(LANGUAGE_MAP)\n",
        "\n",
        "print(\"\\nMODEL_REGISTRY:\")\n",
        "display(MODEL_REGISTRY)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LANGUAGE_MAP:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'en': ('English', 'en'),\n",
              " 'hi': ('Hindi', 'hi'),\n",
              " 'fr': ('French', 'fr'),\n",
              " 'de': ('German', 'de'),\n",
              " 'es': ('Spanish', 'es'),\n",
              " 'zh': ('Chinese', 'zh'),\n",
              " 'ja': ('Japanese', 'ja'),\n",
              " 'ko': ('Korean', 'ko'),\n",
              " 'mr': ('Marathi', 'mr'),\n",
              " 'gu': ('Gujarati', 'gu'),\n",
              " 'ta': ('Tamil', 'ta'),\n",
              " 'ml': ('Malayalam', 'ml')}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MODEL_REGISTRY:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'facebook/m2m100_418M': {'type': 'm2m',\n",
              "  'lang_map': {'en': 'en',\n",
              "   'hi': 'hi',\n",
              "   'fr': 'fr',\n",
              "   'de': 'de',\n",
              "   'es': 'es',\n",
              "   'zh': 'zh',\n",
              "   'ja': 'ja',\n",
              "   'ko': 'ko',\n",
              "   'mr': 'mr',\n",
              "   'gu': 'gu',\n",
              "   'ta': 'tam_Taml',\n",
              "   'ml': 'mal_Mlym'}},\n",
              " 'facebook/nllb-200-distilled-600M': {'type': 'nllb',\n",
              "  'lang_map': {'en': 'eng_Latn',\n",
              "   'hi': 'hin_Deva',\n",
              "   'fr': 'fra_Latn',\n",
              "   'de': 'deu_Latn',\n",
              "   'es': 'spa_Latn',\n",
              "   'zh': 'zho_Hans',\n",
              "   'ja': 'jpn_Jpan',\n",
              "   'ko': 'kor_Hang',\n",
              "   'mr': 'mar_Deva',\n",
              "   'gu': 'guj_Gujr',\n",
              "   'ta': 'tam_Taml',\n",
              "   'ml': 'mal_Mlym'}}}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8608201e",
        "outputId": "754c64f2-c84a-475c-bda1-bdd41a466076"
      },
      "source": [
        "print('Demonstrating `apply_glossary` function:')\n",
        "\n",
        "sample_text = \"The capital of France is Paris. OpenAI is a company that works on AI.\"\n",
        "glossary_rules = \"Paris=The City of Lights\\nOpenAI=‡§ì‡§™‡§®‡§è‡§Ü‡§à\\nAI=Artificial Intelligence\"\n",
        "\n",
        "# Call the apply_glossary function with sample text and rules\n",
        "processed_text = apply_glossary(sample_text, glossary_rules)\n",
        "\n",
        "print(\"\\nOriginal Text:\")\n",
        "print(sample_text)\n",
        "\n",
        "print(\"\\nGlossary Rules:\")\n",
        "print(glossary_rules)\n",
        "\n",
        "print(\"\\nProcessed Text (after applying glossary):\")\n",
        "print(processed_text)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demonstrating `apply_glossary` function:\n",
            "\n",
            "Original Text:\n",
            "The capital of France is Paris. OpenAI is a company that works on AI.\n",
            "\n",
            "Glossary Rules:\n",
            "Paris=The City of Lights\n",
            "OpenAI=‡§ì‡§™‡§®‡§è‡§Ü‡§à\n",
            "AI=Artificial Intelligence\n",
            "\n",
            "Processed Text (after applying glossary):\n",
            "The capital of France is The City of Lights. ‡§ì‡§™‡§®‡§è‡§Ü‡§à is a company that works on Artificial Intelligence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54bd9af8",
        "outputId": "858ac940-ba1f-4cc9-9a6f-4f2dc77d0a04"
      },
      "source": [
        "print(\"Definition of do_clear function:\\n\")\n",
        "def do_clear():\n",
        "    HISTORY.clear()\n",
        "    return \"### Recent Translations\\nNo translations yet.\"\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Definition of do_clear function:\n",
            "\n"
          ]
        }
      ]
    }
  ]
}